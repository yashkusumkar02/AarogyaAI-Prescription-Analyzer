import warnings
warnings.filterwarnings("ignore", message="Couldn't find ffmpeg or avconv")

import streamlit as st
import pytesseract
from PIL import Image
import cv2
import numpy as np
import google.generativeai as genai
from gtts import gTTS
import os
from io import BytesIO
import re
from dotenv import load_dotenv
from deep_translator import GoogleTranslator
import speech_recognition as sr
from pydub import AudioSegment
from pydub.playback import play
AudioSegment.converter = "path_to_your_ffmpeg"  # Set this if you have ffmpeg in a non-standard location

# Load environment variables
load_dotenv()

# --------------------------
# Configuration
# --------------------------
st.set_page_config(
    page_title="AarogyaAI Pro - Advanced Prescription Analyzer",
    page_icon="üè•",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Initialize services with error handling
try:
    GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')
    if not GEMINI_API_KEY:
        st.error("Missing Gemini API key in .env file")
        st.stop()
    
    genai.configure(api_key=GEMINI_API_KEY)
    
    # Using Gemini 1.5 Flash model
    generation_config = {
        "temperature": 0.7,
        "top_p": 1,
        "top_k": 32,
        "max_output_tokens": 4096,
    }
    
    safety_settings = [
        {
            "category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
        {
            "category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"
        },
    ]

    medical_model = genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        generation_config=generation_config,
        safety_settings=safety_settings
    )
    
    chat_model = genai.GenerativeModel(
        model_name="gemini-1.5-flash",
        generation_config=generation_config,
        safety_settings=safety_settings
    )
    
    # Set Tesseract path
    pytesseract.pytesseract.tesseract_cmd = os.getenv('TESSERACT_PATH', r'C:\Program Files\Tesseract-OCR\tesseract.exe')
    
except Exception as e:
    st.error(f"Service initialization failed: {str(e)}")
    st.stop()

# --------------------------
# Core Functions
# --------------------------
def text_to_speech(text, lang='en'):
    """Convert text to speech with error handling"""
    try:
        tts = gTTS(text=text, lang=lang, slow=False)
        audio_bytes = BytesIO()
        tts.write_to_fp(audio_bytes)
        audio_bytes.seek(0)
        return audio_bytes
    except Exception as e:
        st.warning(f"Voice generation failed: {str(e)}")
        return None

def speech_to_text(lang='en'):
    """Convert speech to text with error handling"""
    r = sr.Recognizer()
    try:
        with sr.Microphone() as source:
            st.info("Listening... Speak now")
            audio = r.listen(source, timeout=5)
            text = r.recognize_google(audio, language=lang)
            return text
    except sr.UnknownValueError:
        st.warning("Could not understand audio")
        return None
    except sr.RequestError as e:
        st.warning(f"Could not request results; {e}")
        return None
    except Exception as e:
        st.warning(f"Voice recognition failed: {str(e)}")
        return None

def load_and_validate_image(uploaded_file):
    """Load and validate the uploaded image file"""
    try:
        img = Image.open(uploaded_file)
        if img.mode in ('RGBA', 'P'):
            img = img.convert('RGB')
        return img
    except Exception as e:
        st.error(f"Failed to load image: {str(e)}")
        return None

def enhance_image(image):
    """Advanced image preprocessing for OCR"""
    try:
        img = np.array(image)
        if len(img.shape) == 2:
            gray = img
        else:
            gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
        
        blur = cv2.GaussianBlur(gray, (3,3), 0)
        thresh = cv2.adaptiveThreshold(blur, 255, 
                                     cv2.ADAPTIVE_THRESH_GAUSSIAN_C,
                                     cv2.THRESH_BINARY, 11, 2)
        kernel = np.ones((1,1), np.uint8)
        processed = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel)
        return Image.fromarray(processed)
    except Exception as e:
        st.error(f"Image processing error: {str(e)}")
        return image

def translate_text(text, target_lang='en'):
    """Translate text with error handling"""
    try:
        if target_lang == 'en':
            return text
        return GoogleTranslator(source='auto', target=target_lang).translate(text)
    except Exception as e:
        st.warning(f"Translation failed: {str(e)}")
        return text

# Complete UI translations for Indian languages
UI_TRANSLATIONS = {
    "English": {
        "title": "üè• AarogyaAI Advanced Prescription Analyzer",
        "patient_profile": "Patient Profile",
        "input_method": "Input Method",
        "image_upload": "Image Upload",
        "text_input": "Text Input",
        "age": "Age",
        "weight": "Weight (kg)",
        "gender": "Gender",
        "male": "Male",
        "female": "Female",
        "other": "Other",
        "allergies": "Allergies",
        "conditions": "Existing Conditions",
        "output_language": "Application Language",
        "prescription_input": "Prescription Input",
        "upload_prescription": "Upload Prescription Image",
        "upload_help": "For best results, use clear, well-lit images",
        "extracted_text": "Extracted Text",
        "enter_prescription": "Enter Prescription Text",
        "enter_placeholder": "Enter prescription details here...",
        "analyze_btn": "Analyze Prescription",
        "no_prescription": "Please enter or upload a prescription",
        "extracting": "Extracting text from image...",
        "no_text": "Could not extract text. Please try a clearer image or use text input.",
        "analyzing": "Analyzing with medical AI...",
        "analysis_results": "Analysis Results",
        "chat_assistant": "Prescription Chat Assistant",
        "chat_prompt": "Ask questions about your analyzed prescription",
        "chat_input": "Ask about your prescription...",
        "voice_input": "üé§ Voice Input",
        "profile_info": "Patient profile will be enabled for text input",
        "voice_instructions": "Click the microphone and speak your question",
        "general_health": "General Health Information",
        "medication_info": "Medication Information",
        "side_effects": "Side Effects",
        "diet_advice": "Diet Advice",
        "exercise_advice": "Exercise Advice",
        "emergency_info": "Emergency Information",
        "clear_chat": "Clear Chat History",
        "prescription_context": "Prescription Context",
        "patient_context": "Patient Context",
        "system_prompt": "System Instructions",
        "chat_history": "Conversation History"
    },
    "Hindi": {
        "title": "üè• ‡§Ü‡§∞‡•ã‡§ó‡•ç‡§Ø‡§è‡§Ü‡§à ‡§â‡§®‡•ç‡§®‡§§ ‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§ï",
        "patient_profile": "‡§∞‡•ã‡§ó‡•Ä ‡§™‡•ç‡§∞‡•ã‡§´‡§º‡§æ‡§á‡§≤",
        "input_method": "‡§á‡§®‡§™‡•Å‡§ü ‡§µ‡§ø‡§ß‡§ø",
        "image_upload": "‡§õ‡§µ‡§ø ‡§Ö‡§™‡§≤‡•ã‡§°",
        "text_input": "‡§™‡§æ‡§† ‡§á‡§®‡§™‡•Å‡§ü",
        "age": "‡§Ü‡§Ø‡•Å",
        "weight": "‡§µ‡§ú‡§® (‡§ï‡§ø‡§≤‡•ã)",
        "gender": "‡§≤‡§ø‡§Ç‡§ó",
        "male": "‡§™‡•Å‡§∞‡•Å‡§∑",
        "female": "‡§Æ‡§π‡§ø‡§≤‡§æ",
        "other": "‡§Ö‡§®‡•ç‡§Ø",
        "allergies": "‡§è‡§≤‡§∞‡•ç‡§ú‡•Ä",
        "conditions": "‡§Æ‡•å‡§ú‡•Ç‡§¶‡§æ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø‡§Ø‡§æ‡§Å",
        "output_language": "‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§® ‡§≠‡§æ‡§∑‡§æ",
        "prescription_input": "‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§á‡§®‡§™‡•Å‡§ü",
        "upload_prescription": "‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§õ‡§µ‡§ø ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "upload_help": "‡§∏‡§∞‡•ç‡§µ‡•ã‡§§‡•ç‡§§‡§Æ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü, ‡§Ö‡§ö‡•ç‡§õ‡•Ä ‡§∞‡•ã‡§∂‡§®‡•Ä ‡§µ‡§æ‡§≤‡•Ä ‡§õ‡§µ‡§ø‡§Ø‡•ã‡§Ç ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç",
        "extracted_text": "‡§®‡§ø‡§ï‡§æ‡§≤‡§æ ‡§ó‡§Ø‡§æ ‡§™‡§æ‡§†",
        "enter_prescription": "‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§™‡§æ‡§† ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§∞‡•á‡§Ç",
        "enter_placeholder": "‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§µ‡§ø‡§µ‡§∞‡§£ ‡§Ø‡§π‡§æ‡§Å ‡§¶‡§∞‡•ç‡§ú ‡§ï‡§∞‡•á‡§Ç...",
        "analyze_btn": "‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§ï‡§æ ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§∞‡•á‡§Ç",
        "no_prescription": "‡§ï‡•É‡§™‡§Ø‡§æ ‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§¶‡§∞‡•ç‡§ú ‡§Ø‡§æ ‡§Ö‡§™‡§≤‡•ã‡§° ‡§ï‡§∞‡•á‡§Ç",
        "extracting": "‡§õ‡§µ‡§ø ‡§∏‡•á ‡§™‡§æ‡§† ‡§®‡§ø‡§ï‡§æ‡§≤‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "no_text": "‡§™‡§æ‡§† ‡§®‡§ø‡§ï‡§æ‡§≤‡§æ ‡§®‡§π‡•Ä‡§Ç ‡§ú‡§æ ‡§∏‡§ï‡§æ‡•§ ‡§ï‡•É‡§™‡§Ø‡§æ ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§õ‡§µ‡§ø ‡§ï‡§æ ‡§™‡•ç‡§∞‡§Ø‡§æ‡§∏ ‡§ï‡§∞‡•á‡§Ç ‡§Ø‡§æ ‡§™‡§æ‡§† ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡•á‡§Ç‡•§",
        "analyzing": "‡§ö‡§ø‡§ï‡§ø‡§§‡•ç‡§∏‡§æ ‡§è‡§Ü‡§à ‡§ï‡•á ‡§∏‡§æ‡§• ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§ï‡§ø‡§Ø‡§æ ‡§ú‡§æ ‡§∞‡§π‡§æ ‡§π‡•à...",
        "analysis_results": "‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§£ ‡§™‡§∞‡§ø‡§£‡§æ‡§Æ",
        "chat_assistant": "‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§ö‡•à‡§ü ‡§∏‡§π‡§æ‡§Ø‡§ï",
        "chat_prompt": "‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§ø‡§§ ‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§™‡•Ç‡§õ‡•á‡§Ç",
        "chat_input": "‡§Ö‡§™‡§®‡•á ‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§™‡•Ç‡§õ‡•á‡§Ç...",
        "voice_input": "üé§ ‡§µ‡•â‡§á‡§∏ ‡§á‡§®‡§™‡•Å‡§ü",
        "profile_info": "‡§™‡§æ‡§† ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡•ã‡§ó‡•Ä ‡§™‡•ç‡§∞‡•ã‡§´‡§º‡§æ‡§á‡§≤ ‡§∏‡§ï‡•ç‡§∑‡§Æ ‡§π‡•ã‡§ó‡§æ",
        "voice_instructions": "‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡•ã‡§® ‡§™‡§∞ ‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§Ö‡§™‡§®‡§æ ‡§™‡•ç‡§∞‡§∂‡•ç‡§® ‡§¨‡•ã‡§≤‡•á‡§Ç",
        "general_health": "‡§∏‡§æ‡§Æ‡§æ‡§®‡•ç‡§Ø ‡§∏‡•ç‡§µ‡§æ‡§∏‡•ç‡§•‡•ç‡§Ø ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä",
        "medication_info": "‡§¶‡§µ‡§æ ‡§ï‡•Ä ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä",
        "side_effects": "‡§¶‡•Å‡§∑‡•ç‡§™‡•ç‡§∞‡§≠‡§æ‡§µ",
        "diet_advice": "‡§Ü‡§π‡§æ‡§∞ ‡§∏‡§≤‡§æ‡§π",
        "exercise_advice": "‡§µ‡•ç‡§Ø‡§æ‡§Ø‡§æ‡§Æ ‡§∏‡§≤‡§æ‡§π",
        "emergency_info": "‡§Ü‡§™‡§æ‡§§‡§ï‡§æ‡§≤‡•Ä‡§® ‡§ú‡§æ‡§®‡§ï‡§æ‡§∞‡•Ä",
        "clear_chat": "‡§ö‡•à‡§ü ‡§á‡§§‡§ø‡§π‡§æ‡§∏ ‡§∏‡§æ‡§´ ‡§ï‡§∞‡•á‡§Ç",
        "prescription_context": "‡§™‡•ç‡§∞‡§ø‡§∏‡•ç‡§ï‡•ç‡§∞‡§ø‡§™‡•ç‡§∂‡§® ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠",
        "patient_context": "‡§∞‡•ã‡§ó‡•Ä ‡§∏‡§Ç‡§¶‡§∞‡•ç‡§≠",
        "system_prompt": "‡§∏‡§ø‡§∏‡•ç‡§ü‡§Æ ‡§®‡§ø‡§∞‡•ç‡§¶‡•á‡§∂",
        "chat_history": "‡§µ‡§æ‡§∞‡•ç‡§§‡§æ‡§≤‡§æ‡§™ ‡§á‡§§‡§ø‡§π‡§æ‡§∏"
    }
}

# Language mapping for gTTS and translation
LANGUAGE_MAPPING = {
    "English": {"code": "en", "display": "English"},
    "Hindi": {"code": "hi", "display": "‡§π‡§ø‡§Ç‡§¶‡•Ä"},
    "Marathi": {"code": "mr", "display": "‡§Æ‡§∞‡§æ‡§†‡•Ä"},
    "Tamil": {"code": "ta", "display": "‡Æ§‡ÆÆ‡Æø‡Æ¥‡Øç"},
    "Telugu": {"code": "te", "display": "‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å"},
    "Kannada": {"code": "kn", "display": "‡≤ï‡≤®‡≥ç‡≤®‡≤°"},
    "Malayalam": {"code": "ml", "display": "‡¥Æ‡¥≤‡¥Ø‡¥æ‡¥≥‡¥Ç"},
    "Bengali": {"code": "bn", "display": "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ"},
    "Gujarati": {"code": "gu", "display": "‡™ó‡´Å‡™ú‡™∞‡™æ‡™§‡´Ä"},
    "Punjabi": {"code": "pa", "display": "‡®™‡©∞‡®ú‡®æ‡®¨‡©Ä"},
    "Odia": {"code": "or", "display": "‡¨ì‡¨°‡¨º‡¨ø‡¨Ü"},
    "Urdu": {"code": "ur", "display": "ÿßÿ±ÿØŸà"},
    "Assamese": {"code": "as", "display": "‡¶Ö‡¶∏‡¶Æ‡ßÄ‡¶Ø‡¶º‡¶æ"},
    "Nepali": {"code": "ne", "display": "‡§®‡•á‡§™‡§æ‡§≤‡•Ä"},
    "Sanskrit": {"code": "sa", "display": "‡§∏‡§Ç‡§∏‡•ç‡§ï‡•É‡§§‡§Æ‡•ç"},
    "French": {"code": "fr", "display": "Fran√ßais"},
    "Spanish": {"code": "es", "display": "Espa√±ol"},
    "German": {"code": "de", "display": "Deutsch"},
    "Chinese": {"code": "zh", "display": "‰∏≠Êñá"},
    "Japanese": {"code": "ja", "display": "Êó•Êú¨Ë™û"},
    "Russian": {"code": "ru", "display": "–†—É—Å—Å–∫–∏–π"},
    "Arabic": {"code": "ar", "display": "ÿßŸÑÿπÿ±ÿ®Ÿäÿ©"}
}

HEALTH_QUESTIONS = {
    "English": [
        "What are the side effects of this medication?",
        "Can I take this with alcohol?",
        "What food should I avoid with these medicines?",
        "When should I take this medicine?",
        "What are the warning signs to watch for?"
    ],
    "Hindi": [
        "‡§á‡§∏ ‡§¶‡§µ‡§æ ‡§ï‡•á ‡§∏‡§æ‡§á‡§° ‡§á‡§´‡•á‡§ï‡•ç‡§ü ‡§ï‡•ç‡§Ø‡§æ ‡§π‡•à‡§Ç?",
        "‡§ï‡•ç‡§Ø‡§æ ‡§Æ‡•à‡§Ç ‡§á‡§∏‡•á ‡§∂‡§∞‡§æ‡§¨ ‡§ï‡•á ‡§∏‡§æ‡§• ‡§≤‡•á ‡§∏‡§ï‡§§‡§æ ‡§π‡•Ç‡§Å?",
        "‡§á‡§® ‡§¶‡§µ‡§æ‡§ì‡§Ç ‡§ï‡•á ‡§∏‡§æ‡§• ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•å‡§® ‡§∏‡•á ‡§ñ‡§æ‡§¶‡•ç‡§Ø ‡§™‡§¶‡§æ‡§∞‡•ç‡§•‡•ã‡§Ç ‡§∏‡•á ‡§¨‡§ö‡§®‡§æ ‡§ö‡§æ‡§π‡§ø‡§è?",
        "‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§π ‡§¶‡§µ‡§æ ‡§ï‡§¨ ‡§≤‡•á‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è?",
        "‡§Æ‡•Å‡§ù‡•á ‡§ï‡§ø‡§® ‡§ö‡•á‡§§‡§æ‡§µ‡§®‡•Ä ‡§∏‡§Ç‡§ï‡•á‡§§‡•ã‡§Ç ‡§™‡§∞ ‡§®‡§ú‡§∞ ‡§∞‡§ñ‡§®‡•Ä ‡§ö‡§æ‡§π‡§ø‡§è?"
    ]
}

# --------------------------
# Main Application
# --------------------------
def main():
    # Initialize session state
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'analysis_done' not in st.session_state:
        st.session_state.analysis_done = False
    if 'voice_input' not in st.session_state:
        st.session_state.voice_input = False
    if 'prescription_text' not in st.session_state:
        st.session_state.prescription_text = ""
    if 'patient_context' not in st.session_state:
        st.session_state.patient_context = {}
    if 'analysis_result' not in st.session_state:
        st.session_state.analysis_result = ""

    # Language selection at the very top
    lang_col, _ = st.columns([1, 4])
    with lang_col:
        selected_lang = st.selectbox(
            "üåê Select Application Language / ‡§è‡§™‡•ç‡§≤‡§ø‡§ï‡•á‡§∂‡§® ‡§≠‡§æ‡§∑‡§æ ‡§ö‡•Å‡§®‡•á‡§Ç",
            sorted(UI_TRANSLATIONS.keys()),
            key='app_language'
        )
    
    # Get translations for selected language
    t = UI_TRANSLATIONS.get(selected_lang, UI_TRANSLATIONS["English"])
    
    # Custom CSS for better UI
    st.markdown("""
    <style>
        .stApp {
            background-color: #f5f9ff;
        }
        .stSidebar {
            background-color: #e6f0ff !important;
        }
        .stButton button {
            background-color: #4a90e2;
            color: white;
            border-radius: 8px;
            padding: 0.5rem 1rem;
        }
        .stButton button:hover {
            background-color: #3a7bc8;
            color: white;
        }
        .stTextInput input, .stTextArea textarea {
            border-radius: 8px;
            border: 1px solid #4a90e2;
        }
        .stSelectbox select {
            border-radius: 8px;
            border: 1px solid #4a90e2;
        }
        .chat-message {
            padding: 1rem;
            border-radius: 12px;
            margin-bottom: 1rem;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .user-message {
            background-color: #e6f0ff;
            margin-left: 20%;
        }
        .assistant-message {
            background-color: #ffffff;
            margin-right: 20%;
        }
        .analysis-card {
            background-color: white;
            padding: 1.5rem;
            border-radius: 12px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
            margin-bottom: 1.5rem;
        }
        .prescription-card {
            background-color: #f0f7ff;
            padding: 1rem;
            border-radius: 8px;
            border-left: 4px solid #4a90e2;
            margin-bottom: 1rem;
        }
    </style>
    """, unsafe_allow_html=True)
    
    st.title(t["title"])
    
    # Sidebar - Patient Profile (only shown for text input)
    with st.sidebar:
        st.header(t["patient_profile"])
        
        input_method = st.radio(
            t["input_method"],
            [t["image_upload"], t["text_input"]],
            index=0,
            key='input_method'
        )
        
        if input_method == t["text_input"]:
            age = st.number_input(t["age"], 1, 120, 30)
            weight = st.number_input(t["weight"], 30, 200, 70)
            gender = st.radio(t["gender"], [t["male"], t["female"], t["other"]])
            allergies = st.multiselect(
                t["allergies"], 
                ["Penicillin", "Sulfa", "NSAIDs", "Iodine", "Latex", "None"]
            )
            conditions = st.multiselect(
                t["conditions"],
                ["Diabetes", "Hypertension", "Asthma", "Heart Disease", "None"]
            )
        else:
            st.info(t["profile_info"])
            age, weight, gender, allergies, conditions = 30, 70, t["male"], [], []
        
        # Language selection for output (always visible)
        output_lang = st.selectbox(
            t["output_language"],
            sorted(LANGUAGE_MAPPING.keys()),
            key='output_language'
        )
        
        # Common health questions
        st.subheader(t["general_health"])
        if st.button(t["medication_info"]):
            st.session_state.chat_history.append({
                "role": "user",
                "content": HEALTH_QUESTIONS.get(output_lang, HEALTH_QUESTIONS["English"])[0]
            })
            st.rerun()
        if st.button(t["side_effects"]):
            st.session_state.chat_history.append({
                "role": "user",
                "content": HEALTH_QUESTIONS.get(output_lang, HEALTH_QUESTIONS["English"])[1]
            })
            st.rerun()
        if st.button(t["diet_advice"]):
            st.session_state.chat_history.append({
                "role": "user",
                "content": HEALTH_QUESTIONS.get(output_lang, HEALTH_QUESTIONS["English"])[2]
            })
            st.rerun()
        
        # Clear chat button
        if st.button(t["clear_chat"]):
            st.session_state.chat_history = []
            st.rerun()
    
    # Main content area
    col1, col2 = st.columns([3, 2])
    
    with col1:
        st.subheader(t["prescription_input"])
        prescription_text = ""
        
        if input_method == t["image_upload"]:
            uploaded_file = st.file_uploader(
                t["upload_prescription"],
                type=["jpg", "jpeg", "png", "pdf"],
                help=t["upload_help"]
            )
            
            if uploaded_file:
                if uploaded_file.type == "application/pdf":
                    st.warning("PDF processing coming soon. Please upload an image file.")
                else:
                    img = load_and_validate_image(uploaded_file)
                    if img:
                        st.image(img, use_container_width=True)
                        with st.spinner(t["extracting"]):
                            enhanced = enhance_image(img)
                            prescription_text = pytesseract.image_to_string(enhanced)
                            st.session_state.prescription_text = prescription_text
                            if prescription_text.strip():
                                st.markdown(f"""
                                <div class="prescription-card">
                                    <strong>{t['extracted_text']}:</strong><br>
                                    {prescription_text}
                                </div>
                                """, unsafe_allow_html=True)
                            else:
                                st.warning(t["no_text"])
        
        else:  # Text Input
            prescription_text = st.text_area(
                t["enter_prescription"],
                height=200,
                placeholder=t["enter_placeholder"],
                key='prescription_text_input'
            )
            st.session_state.prescription_text = prescription_text
        
        # Analysis button
        if st.button(t["analyze_btn"], type="primary", key='analyze_btn'):
            if not st.session_state.prescription_text.strip():
                st.warning(t["no_prescription"])
            else:
                with st.spinner(t["analyzing"]):
                    try:
                        # Prepare context
                        lang_code = LANGUAGE_MAPPING[output_lang]["code"]
                        context = {
                            'age': age,
                            'weight': weight,
                            'gender': gender,
                            'allergies': allergies,
                            'conditions': conditions,
                            'language': lang_code
                        }
                        st.session_state.patient_context = context
                        
                        # Generate prompt
                        prompt = f"""
                        Analyze this prescription for a {context['age']} year old {context['gender']}:
                        
                        **Patient Details:**
                        - Weight: {context['weight']} kg
                        - Allergies: {', '.join(context['allergies']) or 'None'}
                        - Conditions: {', '.join(context['conditions']) or 'None'}
                        
                        **Prescription:**
                        {st.session_state.prescription_text}
                        
                        Provide comprehensive analysis in {output_lang} covering:
                        1. All medications identified with dosage information
                        2. Verification if dosage is age/weight appropriate
                        3. Potential drug interactions
                        4. Possible allergy/condition conflicts
                        5. Clear patient instructions in simple terms
                        6. Red flags requiring immediate medical attention
                        
                        Format your response with:
                        - Clear section headings
                        - Bullet points for readability
                        - Relevant emojis for visual cues
                        - Warning symbols for critical information
                        """
                        
                        # Get analysis using Gemini 1.5 Flash
                        response = medical_model.generate_content(prompt)
                        analysis = response.text
                        
                        # Translate if needed
                        if lang_code != 'en':
                            analysis = translate_text(analysis, lang_code)
                        
                        # Store analysis in session state
                        st.session_state.analysis_result = analysis
                        st.session_state.analysis_done = True
                        
                        # Rerun to update the display
                        st.rerun()
                    
                    except Exception as e:
                        st.error(f"Analysis failed: {str(e)}")
        
        # Display analysis results if available
        if st.session_state.get('analysis_done', False):
            st.subheader(f"{t['analysis_results']} ({output_lang})")
            
            # Create a nice card for the analysis
            with st.container():
                st.markdown(f"""
                <div class="analysis-card">
                    {st.session_state.analysis_result}
                </div>
                """, unsafe_allow_html=True)
                
                # Voice output
                if len(st.session_state.analysis_result) > 0:
                    lang_code = LANGUAGE_MAPPING[output_lang]["code"]
                    audio = text_to_speech(
                        st.session_state.analysis_result[:500],  # First 500 chars
                        lang_code
                    )
                    if audio:
                        st.audio(audio, format='audio/mp3')
    
    # Enhanced Chat interface (right column)
    with col2:
        st.subheader(t["chat_assistant"])
        
        # Display context information
        if st.session_state.get('analysis_done', False):
            with st.expander(t["prescription_context"]):
                st.write(f"**{t['patient_context']}**")
                st.json(st.session_state.patient_context)
                st.write("**Prescription Excerpt:**")
                st.text(st.session_state.prescription_text[:200] + "...")
        
        st.info(t["chat_prompt"])
        
        # Voice input button
        if st.button(t["voice_input"]):
            st.session_state.voice_input = True
        
        if st.session_state.get('voice_input', False):
            lang_code = LANGUAGE_MAPPING[output_lang]["code"]
            voice_text = speech_to_text(lang_code)
            if voice_text:
                st.session_state.chat_history.append({
                    "role": "user",
                    "content": voice_text
                })
                st.session_state.voice_input = False
                st.rerun()
        
        # Display chat history
        for msg in st.session_state.chat_history:
            if msg["role"] == "user":
                st.markdown(f"""
                <div class="chat-message user-message">
                    <strong>You:</strong><br>
                    {msg["content"]}
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown(f"""
                <div class="chat-message assistant-message">
                    <strong>AarogyaAI:</strong><br>
                    {msg["content"]}
                </div>
                """, unsafe_allow_html=True)
                
                # Add voice output for assistant messages
                if msg["role"] == "assistant":
                    lang_code = LANGUAGE_MAPPING[output_lang]["code"]
                    audio = text_to_speech(msg["content"], lang_code)
                    if audio:
                        st.audio(audio, format='audio/mp3')
        
        # Chat input
        if prompt := st.chat_input(t["chat_input"]):
            # Add user message to chat history
            st.session_state.chat_history.append({"role": "user", "content": prompt})
            
            # Generate response
            lang_code = LANGUAGE_MAPPING[output_lang]["code"]
            context = st.session_state.get('patient_context', {
                'age': age,
                'weight': weight,
                'gender': gender,
                'allergies': allergies,
                'conditions': conditions,
                'language': lang_code
            })
            
            # Include prescription context if available
            prescription_context = ""
            if st.session_state.get('analysis_done', False):
                prescription_context = f"""
                **Prescription Context:**
                {st.session_state.prescription_text[:1000]}
                
                **Previous Analysis:**
                {st.session_state.analysis_result[:1000]}
                """
            
            # System prompt for the AI
            system_prompt = f"""
            You are a professional medical assistant named AarogyaAI helping a {context['age']} year old {context['gender']} patient understand their prescription.
            
            **Patient Details:**
            - Weight: {context['weight']} kg
            - Allergies: {', '.join(context['allergies']) or 'None'}
            - Existing Conditions: {', '.join(context['conditions']) or 'None'}
            
            **Instructions:**
            1. Always respond in {output_lang} unless specifically asked to use another language
            2. Focus on the prescription content and patient context
            3. Provide accurate, medically verified information
            4. Explain complex medical terms in simple language
            5. Highlight important warnings clearly
            6. Be empathetic and professional
            7. If unsure about something, say you don't know rather than guessing
            8. Format responses clearly with bullet points when appropriate
            
            {prescription_context}
            """
            
            # Prepare the full prompt for Gemini
            chat_prompt = {
                "system_instruction": system_prompt,
                "parts": [{"text": prompt}]
            }
            
            try:
                with st.spinner("Generating response..."):
                    # Generate response using Gemini 1.5 Flash
                    response = chat_model.generate_content(chat_prompt)
                    answer = response.text
                    
                    # Translate if needed
                    if lang_code != 'en':
                        answer = translate_text(answer, lang_code)
                    
                    # Add to chat history
                    st.session_state.chat_history.append({"role": "assistant", "content": answer})
                    
                    # Rerun to display new messages
                    st.rerun()
            
            except Exception as e:
                st.error(f"Chat failed: {str(e)}")

if __name__ == "__main__":
    main()